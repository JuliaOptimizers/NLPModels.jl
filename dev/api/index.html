<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · NLPModels.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/style.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="NLPModels.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">NLPModels.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../models/">Models</a></li><li><a class="tocitem" href="../tools/">Tools</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li class="is-active"><a class="tocitem" href>API</a><ul class="internal"><li><a class="tocitem" href="#Reference-guide-1"><span>Reference guide</span></a></li><li><a class="tocitem" href="#API-for-NLSModels-1"><span>API for NLSModels</span></a></li><li><a class="tocitem" href="#AbstractNLPModel-functions-1"><span>AbstractNLPModel functions</span></a></li><li><a class="tocitem" href="#AbstractNLSModel-1"><span>AbstractNLSModel</span></a></li><li><a class="tocitem" href="#Derivative-Checker-1"><span>Derivative Checker</span></a></li><li><a class="tocitem" href="#Internal-1"><span>Internal</span></a></li></ul></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="API-1"><a class="docs-heading-anchor" href="#API-1">API</a><a class="docs-heading-anchor-permalink" href="#API-1" title="Permalink"></a></h1><p>As stated in the <a href="../#Home-1">Home</a> page, we consider the nonlinear optimization problem in the following format:</p><div>\[\begin{align*}
\min \quad &amp; f(x) \\
&amp; c_L \leq c(x) \leq c_U \\
&amp; \ell \leq x \leq u.
\end{align*}\]</div><p>To develop an optimization algorithm, we are usually worried not only with <span>$f(x)$</span> and <span>$c(x)$</span>, but also with their derivatives. Namely,</p><ul><li><span>$\nabla f(x)$</span>, the gradient of <span>$f$</span> at the point <span>$x$</span>;</li><li><span>$\nabla^2 f(x)$</span>, the Hessian of <span>$f$</span> at the point <span>$x$</span>;</li><li><span>$J(x) = \nabla c(x)$</span>, the Jacobian of <span>$c$</span> at the point <span>$x$</span>;</li><li><span>$\nabla^2 f(x) + \sum_{i=1}^m \lambda_i \nabla^2 c_i(x)$</span>, the Hessian of the Lagrangian function at the point <span>$(x,\lambda)$</span>.</li></ul><p>There are many ways to access some of these values, so here is a little reference guide.</p><h2 id="Reference-guide-1"><a class="docs-heading-anchor" href="#Reference-guide-1">Reference guide</a><a class="docs-heading-anchor-permalink" href="#Reference-guide-1" title="Permalink"></a></h2><p>The following naming should be easy enough to follow. If not, click on the link and go to the description.</p><ul><li><code>!</code> means inplace;</li><li><code>_coord</code> means coordinate format;</li><li><code>prod</code> means matrix-vector product;</li><li><code>_op</code> means operator (as in <a href="https://github.com/JuliaSmoothOptimizers/LinearOperators.jl">LinearOperators.jl</a>).</li></ul><p>Feel free to open an issue to suggest other methods that should apply to all NLPModels instances.</p><table><tr><th style="text-align: right">Function</th><th style="text-align: right">NLPModels function</th></tr><tr><td style="text-align: right"><span>$f(x)$</span></td><td style="text-align: right"><a href="#NLPModels.obj"><code>obj</code></a>, <a href="#NLPModels.objgrad"><code>objgrad</code></a>, <a href="#NLPModels.objgrad!"><code>objgrad!</code></a>, <a href="#NLPModels.objcons"><code>objcons</code></a>, <a href="#NLPModels.objcons!"><code>objcons!</code></a></td></tr><tr><td style="text-align: right"><span>$\nabla f(x)$</span></td><td style="text-align: right"><a href="#NLPModels.grad"><code>grad</code></a>, <a href="#NLPModels.grad!"><code>grad!</code></a>, <a href="#NLPModels.objgrad"><code>objgrad</code></a>, <a href="#NLPModels.objgrad!"><code>objgrad!</code></a></td></tr><tr><td style="text-align: right"><span>$\nabla^2 f(x)$</span></td><td style="text-align: right"><a href="#NLPModels.hess"><code>hess</code></a>, <a href="#NLPModels.hess_op"><code>hess_op</code></a>, <a href="#NLPModels.hess_op!"><code>hess_op!</code></a>, <a href="#NLPModels.hess_coord"><code>hess_coord</code></a>, <a href="#NLPModels.hess_coord"><code>hess_coord</code></a>, <a href="#NLPModels.hess_structure"><code>hess_structure</code></a>, <a href="#NLPModels.hess_structure!"><code>hess_structure!</code></a>, <a href="#NLPModels.hprod"><code>hprod</code></a>, <a href="#NLPModels.hprod!"><code>hprod!</code></a></td></tr><tr><td style="text-align: right"><span>$c(x)$</span></td><td style="text-align: right"><a href="#NLPModels.cons"><code>cons</code></a>, <a href="#NLPModels.cons!"><code>cons!</code></a>, <a href="#NLPModels.objcons"><code>objcons</code></a>, <a href="#NLPModels.objcons!"><code>objcons!</code></a></td></tr><tr><td style="text-align: right"><span>$J(x)$</span></td><td style="text-align: right"><a href="#NLPModels.jac"><code>jac</code></a>, <a href="#NLPModels.jac_op"><code>jac_op</code></a>, <a href="#NLPModels.jac_op!"><code>jac_op!</code></a>, <a href="#NLPModels.jac_coord"><code>jac_coord</code></a>, <a href="#NLPModels.jac_coord!"><code>jac_coord!</code></a>, <a href="#NLPModels.jac_structure"><code>jac_structure</code></a>, <a href="#NLPModels.jprod"><code>jprod</code></a>, <a href="#NLPModels.jprod!"><code>jprod!</code></a>, <a href="#NLPModels.jtprod"><code>jtprod</code></a>, <a href="#NLPModels.jtprod!"><code>jtprod!</code></a></td></tr><tr><td style="text-align: right"><span>$\nabla^2 L(x,y)$</span></td><td style="text-align: right"><a href="#NLPModels.hess"><code>hess</code></a>, <a href="#NLPModels.hess_op"><code>hess_op</code></a>, <a href="#NLPModels.hess_coord"><code>hess_coord</code></a>, <a href="#NLPModels.hess_coord!"><code>hess_coord!</code></a>, <a href="#NLPModels.hess_structure"><code>hess_structure</code></a>, <a href="#NLPModels.hess_structure!"><code>hess_structure!</code></a>, <a href="#NLPModels.hprod"><code>hprod</code></a>, <a href="#NLPModels.hprod!"><code>hprod!</code></a></td></tr></table><h2 id="API-for-NLSModels-1"><a class="docs-heading-anchor" href="#API-for-NLSModels-1">API for NLSModels</a><a class="docs-heading-anchor-permalink" href="#API-for-NLSModels-1" title="Permalink"></a></h2><p>For the Nonlinear Least Squares models, <span>$f(x) = \Vert F(x)\Vert^2$</span>, and these models have additional function to access the residual value and its derivatives. Namely,</p><ul><li><span>$J_F(x) = \nabla F(x)$</span></li><li><span>$\nabla^2 F_i(x)$</span></li></ul><table><tr><th style="text-align: right">Function</th><th style="text-align: right">function</th></tr><tr><td style="text-align: right"><span>$F(x)$</span></td><td style="text-align: right"><a href="#NLPModels.residual"><code>residual</code></a>, <a href="#NLPModels.residual!"><code>residual!</code></a></td></tr><tr><td style="text-align: right"><span>$J_F(x)$</span></td><td style="text-align: right"><a href="#NLPModels.jac_residual"><code>jac_residual</code></a>, <a href="#NLPModels.jac_coord_residual"><code>jac_coord_residual</code></a>, <a href="#NLPModels.jac_coord_residual!"><code>jac_coord_residual!</code></a>, <a href="#NLPModels.jac_structure_residual"><code>jac_structure_residual</code></a>, <a href="#NLPModels.jprod_residual"><code>jprod_residual</code></a>, <a href="#NLPModels.jprod_residual!"><code>jprod_residual!</code></a>, <a href="#NLPModels.jtprod_residual"><code>jtprod_residual</code></a>, <a href="#NLPModels.jtprod_residual!"><code>jtprod_residual!</code></a>, <a href="#NLPModels.jac_op_residual"><code>jac_op_residual</code></a>, <a href="#NLPModels.jac_op_residual!"><code>jac_op_residual!</code></a></td></tr><tr><td style="text-align: right"><span>$\nabla^2 F_i(x)$</span></td><td style="text-align: right"><a href="#NLPModels.hess_residual"><code>hess_residual</code></a>, <a href="#NLPModels.hess_coord_residual"><code>hess_coord_residual</code></a>, <a href="#NLPModels.hess_coord_residual!"><code>hess_coord_residual!</code></a>, <a href="#NLPModels.hess_structure_residual"><code>hess_structure_residual</code></a>, <a href="#NLPModels.hess_structure_residual!"><code>hess_structure_residual!</code></a>, <a href="#NLPModels.jth_hess_residual"><code>jth_hess_residual</code></a>, <a href="#NLPModels.hprod_residual"><code>hprod_residual</code></a>, <a href="#NLPModels.hprod_residual!"><code>hprod_residual!</code></a>, <a href="#NLPModels.hess_op_residual"><code>hess_op_residual</code></a>, <a href="#NLPModels.hess_op_residual!"><code>hess_op_residual!</code></a></td></tr></table><h2 id="AbstractNLPModel-functions-1"><a class="docs-heading-anchor" href="#AbstractNLPModel-functions-1">AbstractNLPModel functions</a><a class="docs-heading-anchor-permalink" href="#AbstractNLPModel-functions-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="NLPModels.obj" href="#NLPModels.obj"><code>NLPModels.obj</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">f = obj(nlp, x)</code></pre><p>Evaluate <span>$f(x)$</span>, the objective function of <code>nlp</code> at <code>x</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.grad" href="#NLPModels.grad"><code>NLPModels.grad</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">g = grad(nlp, x)</code></pre><p>Evaluate <span>$∇f(x)$</span>, the gradient of the objective function at <code>x</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.grad!" href="#NLPModels.grad!"><code>NLPModels.grad!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">g = grad!(nlp, x, g)</code></pre><p>Evaluate <span>$∇f(x)$</span>, the gradient of the objective function at <code>x</code> in place.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.objgrad" href="#NLPModels.objgrad"><code>NLPModels.objgrad</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">f, g = objgrad(nlp, x)</code></pre><p>Evaluate <span>$f(x)$</span> and <span>$∇f(x)$</span> at <code>x</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.objgrad!" href="#NLPModels.objgrad!"><code>NLPModels.objgrad!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">f, g = objgrad!(nlp, x, g)</code></pre><p>Evaluate <span>$f(x)$</span> and <span>$∇f(x)$</span> at <code>x</code>. <code>g</code> is overwritten with the value of <span>$∇f(x)$</span>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.cons" href="#NLPModels.cons"><code>NLPModels.cons</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">c = cons(nlp, x)</code></pre><p>Evaluate <span>$c(x)$</span>, the constraints at <code>x</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.cons!" href="#NLPModels.cons!"><code>NLPModels.cons!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">c = cons!(nlp, x, c)</code></pre><p>Evaluate <span>$c(x)$</span>, the constraints at <code>x</code> in place.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.objcons" href="#NLPModels.objcons"><code>NLPModels.objcons</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">f, c = objcons(nlp, x)</code></pre><p>Evaluate <span>$f(x)$</span> and <span>$c(x)$</span> at <code>x</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.objcons!" href="#NLPModels.objcons!"><code>NLPModels.objcons!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">f = objcons!(nlp, x, c)</code></pre><p>Evaluate <span>$f(x)$</span> and <span>$c(x)$</span> at <code>x</code>. <code>c</code> is overwritten with the value of <span>$c(x)$</span>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_coord" href="#NLPModels.jac_coord"><code>NLPModels.jac_coord</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">vals = jac_coord(nlp, x)</code></pre><p>Evaluate <span>$∇c(x)$</span>, the constraint&#39;s Jacobian at <code>x</code> in sparse coordinate format.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_coord!" href="#NLPModels.jac_coord!"><code>NLPModels.jac_coord!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">vals = jac_coord!(nlp, x, vals)</code></pre><p>Evaluate <span>$∇c(x)$</span>, the constraint&#39;s Jacobian at <code>x</code> in sparse coordinate format, rewriting <code>vals</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_structure" href="#NLPModels.jac_structure"><code>NLPModels.jac_structure</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">(rows,cols) = jac_structure(nlp)</code></pre><p>Return the structure of the constraint&#39;s Jacobian in sparse coordinate format.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_structure!" href="#NLPModels.jac_structure!"><code>NLPModels.jac_structure!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">jac_structure!(nlp, rows, cols)</code></pre><p>Return the structure of the constraint&#39;s Jacobian in sparse coordinate format in place.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac" href="#NLPModels.jac"><code>NLPModels.jac</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Jx = jac(nlp, x)</code></pre><p>Evaluate <span>$∇c(x)$</span>, the constraint&#39;s Jacobian at <code>x</code> as a sparse matrix.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_op" href="#NLPModels.jac_op"><code>NLPModels.jac_op</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">J = jac_op(nlp, x)</code></pre><p>Return the Jacobian at <code>x</code> as a linear operator. The resulting object may be used as if it were a matrix, e.g., <code>J * v</code> or <code>J&#39; * v</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_op!" href="#NLPModels.jac_op!"><code>NLPModels.jac_op!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">J = jac_op!(nlp, x, Jv, Jtv)</code></pre><p>Return the Jacobian at <code>x</code> as a linear operator. The resulting object may be used as if it were a matrix, e.g., <code>J * v</code> or <code>J&#39; * v</code>. The values <code>Jv</code> and <code>Jtv</code> are used as preallocated storage for the operations.</p></div></section><section><div><pre><code class="language-none">J = jac_op!(nlp, rows, cols, vals, Jv, Jtv)</code></pre><p>Return the Jacobian given by <code>(rows, cols, vals)</code> as a linear operator. The resulting object may be used as if it were a matrix, e.g., <code>J * v</code> or <code>J&#39; * v</code>. The values <code>Jv</code> and <code>Jtv</code> are used as preallocated storage for the operations.</p></div></section><section><div><pre><code class="language-none">J = jac_op!(nlp, x, rows, cols, Jv, Jtv)</code></pre><p>Return the Jacobian at <code>x</code> as a linear operator. The resulting object may be used as if it were a matrix, e.g., <code>J * v</code> or <code>J&#39; * v</code>. <code>(rows, cols)</code> should be the sparsity structure of the Jacobian. The values <code>Jv</code> and <code>Jtv</code> are used as preallocated storage for the operations.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jprod" href="#NLPModels.jprod"><code>NLPModels.jprod</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Jv = jprod(nlp, x, v)</code></pre><p>Evaluate <span>$∇c(x)v$</span>, the Jacobian-vector product at <code>x</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jprod!" href="#NLPModels.jprod!"><code>NLPModels.jprod!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Jv = jprod!(nlp, x, v, Jv)</code></pre><p>Evaluate <span>$∇c(x)v$</span>, the Jacobian-vector product at <code>x</code> in place.</p></div></section><section><div><pre><code class="language-none">Jv = jprod!(nlp, rows, cols, vals, v, Jv)</code></pre><p>Evaluate <span>$∇c(x)v$</span>, the Jacobian-vector product, where the Jacobian is given by <code>(rows, cols, vals)</code> in triplet format.</p></div></section><section><div><pre><code class="language-none">Jv = jprod!(nlp, x, rows, cols, v, Jv)</code></pre><p>Evaluate <span>$∇c(x)v$</span>, the Jacobian-vector product at <code>x</code> in place. <code>(rows, cols)</code> should be the Jacobian structure in triplet format.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jtprod" href="#NLPModels.jtprod"><code>NLPModels.jtprod</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Jtv = jtprod(nlp, x, v, Jtv)</code></pre><p>Evaluate <span>$∇c(x)^Tv$</span>, the transposed-Jacobian-vector product at <code>x</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jtprod!" href="#NLPModels.jtprod!"><code>NLPModels.jtprod!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Jtv = jtprod!(nlp, x, v, Jtv)</code></pre><p>Evaluate <span>$∇c(x)^Tv$</span>, the transposed-Jacobian-vector product at <code>x</code> in place.</p></div></section><section><div><pre><code class="language-none">Jtv = jtprod!(nlp, rows, cols, vals, v, Jtv)</code></pre><p>Evaluate <span>$∇c(x)^Tv$</span>, the transposed-Jacobian-vector product, where the Jacobian is given by <code>(rows, cols, vals)</code> in triplet format.</p></div></section><section><div><pre><code class="language-none">Jtv = jtprod!(nlp, x, rows, cols, v, Jtv)</code></pre><p>Evaluate <span>$∇c(x)^Tv$</span>, the transposed-Jacobian-vector product at <code>x</code> in place. <code>(rows, cols)</code> should be the Jacobian structure in triplet format.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_coord" href="#NLPModels.hess_coord"><code>NLPModels.hess_coord</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">vals = hess_coord(nlp, x; obj_weight=1.0)</code></pre><p>Evaluate the objective Hessian at <code>x</code> in sparse coordinate format, with objective function scaled by <code>obj_weight</code>, i.e.,</p><div>\[σ ∇²f(x),\]</div><p>with <code>σ = obj_weight</code> . Only the lower triangle is returned.</p></div></section><section><div><pre><code class="language-none">vals = hess_coord(nlp, x, y; obj_weight=1.0)</code></pre><p>Evaluate the Lagrangian Hessian at <code>(x,y)</code> in sparse coordinate format, with objective function scaled by <code>obj_weight</code>, i.e.,</p><div>\[∇²L(x,y) = σ ∇²f(x) + ∑ᵢ yᵢ ∇²cᵢ(x),\]</div><p>with <code>σ = obj_weight</code> . Only the lower triangle is returned.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_coord!" href="#NLPModels.hess_coord!"><code>NLPModels.hess_coord!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">vals = hess_coord!(nlp, x, vals; obj_weight=1.0)</code></pre><p>Evaluate the objective Hessian at <code>x</code> in sparse coordinate format, with objective function scaled by <code>obj_weight</code>, i.e.,</p><div>\[σ ∇²f(x),\]</div><p>with <code>σ = obj_weight</code> , rewriting <code>vals</code>. Only the lower triangle is returned.</p></div></section><section><div><pre><code class="language-none">vals = hess_coord!(nlp, x, y, vals; obj_weight=1.0)</code></pre><p>Evaluate the Lagrangian Hessian at <code>(x,y)</code> in sparse coordinate format, with objective function scaled by <code>obj_weight</code>, i.e.,</p><div>\[∇²L(x,y) = σ ∇²f(x) + ∑ᵢ yᵢ ∇²cᵢ(x),\]</div><p>with <code>σ = obj_weight</code> , rewriting <code>vals</code>. Only the lower triangle is returned.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_structure" href="#NLPModels.hess_structure"><code>NLPModels.hess_structure</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">(rows,cols) = hess_structure(nlp)</code></pre><p>Return the structure of the Lagrangian Hessian in sparse coordinate format.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_structure!" href="#NLPModels.hess_structure!"><code>NLPModels.hess_structure!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hess_structure!(nlp, rows, cols)</code></pre><p>Return the structure of the Lagrangian Hessian in sparse coordinate format in place.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess" href="#NLPModels.hess"><code>NLPModels.hess</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Hx = hess(nlp, x; obj_weight=1.0)</code></pre><p>Evaluate the objective Hessian at <code>x</code> as a sparse matrix, with objective function scaled by <code>obj_weight</code>, i.e.,</p><div>\[σ ∇²f(x),\]</div><p>with <code>σ = obj_weight</code> . Only the lower triangle is returned.</p></div></section><section><div><pre><code class="language-none">Hx = hess(nlp, x, y; obj_weight=1.0)</code></pre><p>Evaluate the Lagrangian Hessian at <code>(x,y)</code> as a sparse matrix, with objective function scaled by <code>obj_weight</code>, i.e.,</p><div>\[∇²L(x,y) = σ ∇²f(x) + ∑ᵢ yᵢ ∇²cᵢ(x),\]</div><p>with <code>σ = obj_weight</code> . Only the lower triangle is returned.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_op" href="#NLPModels.hess_op"><code>NLPModels.hess_op</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">H = hess_op(nlp, x; obj_weight=1.0)</code></pre><p>Return the objective Hessian at <code>x</code> with objective function scaled by <code>obj_weight</code> as a linear operator. The resulting object may be used as if it were a matrix, e.g., <code>H * v</code>. The linear operator H represents</p><div>\[σ ∇²f(x),\]</div><p>with <code>σ = obj_weight</code> .</p></div></section><section><div><pre><code class="language-none">H = hess_op(nlp, x, y; obj_weight=1.0)</code></pre><p>Return the Lagrangian Hessian at <code>(x,y)</code> with objective function scaled by <code>obj_weight</code> as a linear operator. The resulting object may be used as if it were a matrix, e.g., <code>H * v</code>. The linear operator H represents</p><div>\[∇²L(x,y) = σ ∇²f(x) + ∑ᵢ yᵢ ∇²cᵢ(x),\]</div><p>with <code>σ = obj_weight</code> .</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_op!" href="#NLPModels.hess_op!"><code>NLPModels.hess_op!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">H = hess_op!(nlp, x, Hv; obj_weight=1.0)</code></pre><p>Return the objective Hessian at <code>x</code> with objective function scaled by <code>obj_weight</code> as a linear operator, and storing the result on <code>Hv</code>. The resulting object may be used as if it were a matrix, e.g., <code>w = H * v</code>. The vector <code>Hv</code> is used as preallocated storage for the operation.  The linear operator H represents</p><div>\[σ ∇²f(x),\]</div><p>with <code>σ = obj_weight</code> .</p></div></section><section><div><pre><code class="language-none">H = hess_op!(nlp, rows, cols, vals, Hv)</code></pre><p>Return the Hessian given by <code>(rows, cols, vals)</code> as a linear operator, and storing the result on <code>Hv</code>. The resulting object may be used as if it were a matrix, e.g., <code>w = H * v</code>.   The vector <code>Hv</code> is used as preallocated storage for the operation.  The linear operator H represents</p><div>\[σ ∇²f(x),\]</div><p>with <code>σ = obj_weight</code> .</p></div></section><section><div><pre><code class="language-none">H = hess_op!(nlp, x, rows, cols, Hv; obj_weight=1.0)</code></pre><p>Return the objective Hessian at <code>x</code> with objective function scaled by <code>obj_weight</code> as a linear operator, and storing the result on <code>Hv</code>. The resulting object may be used as if it were a matrix, e.g., <code>w = H * v</code>. <code>(rows, cols)</code> should be the sparsity structure of the Hessian. The vector <code>Hv</code> is used as preallocated storage for the operation.  The linear operator H represents</p><div>\[σ ∇²f(x),\]</div><p>with <code>σ = obj_weight</code> .</p></div></section><section><div><pre><code class="language-none">H = hess_op!(nlp, x, y, Hv; obj_weight=1.0)</code></pre><p>Return the Lagrangian Hessian at <code>(x,y)</code> with objective function scaled by <code>obj_weight</code> as a linear operator, and storing the result on <code>Hv</code>. The resulting object may be used as if it were a matrix, e.g., <code>w = H * v</code>. The vector <code>Hv</code> is used as preallocated storage for the operation.  The linear operator H represents</p><div>\[∇²L(x,y) = σ ∇²f(x) + ∑ᵢ yᵢ ∇²cᵢ(x),\]</div><p>with <code>σ = obj_weight</code> .</p></div></section><section><div><pre><code class="language-none">H = hess_op!(nlp, x, y, rows, cols, Hv; obj_weight=1.0)</code></pre><p>Return the Lagrangian Hessian at <code>(x,y)</code> with objective function scaled by <code>obj_weight</code> as a linear operator, and storing the result on <code>Hv</code>. The resulting object may be used as if it were a matrix, e.g., <code>w = H * v</code>. <code>(rows, cols)</code> should be the sparsity structure of the Hessian. The vector <code>Hv</code> is used as preallocated storage for the operation.  The linear operator H represents</p><div>\[σ ∇²f(x),\]</div><p>with <code>σ = obj_weight</code> .</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hprod" href="#NLPModels.hprod"><code>NLPModels.hprod</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Hv = hprod(nlp, x, v; obj_weight=1.0)</code></pre><p>Evaluate the product of the objective Hessian at <code>x</code> with the vector <code>v</code>, with objective function scaled by <code>obj_weight</code>, where the objective Hessian is</p><div>\[σ ∇²f(x),\]</div><p>with <code>σ = obj_weight</code> .</p></div></section><section><div><pre><code class="language-none">Hv = hprod(nlp, x, y, v; obj_weight=1.0)</code></pre><p>Evaluate the product of the Lagrangian Hessian at <code>(x,y)</code> with the vector <code>v</code>, with objective function scaled by <code>obj_weight</code>, where the Lagrangian Hessian is</p><div>\[∇²L(x,y) = σ ∇²f(x) + ∑ᵢ yᵢ ∇²cᵢ(x),\]</div><p>with <code>σ = obj_weight</code> .</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hprod!" href="#NLPModels.hprod!"><code>NLPModels.hprod!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Hv = hprod!(nlp, x, v, Hv; obj_weight=1.0)</code></pre><p>Evaluate the product of the objective Hessian at <code>x</code> with the vector <code>v</code> in place, with objective function scaled by <code>obj_weight</code>, where the objective Hessian is</p><div>\[σ ∇²f(x),\]</div><p>with <code>σ = obj_weight</code> .</p></div></section><section><div><pre><code class="language-none">Hv = hprod!(nlp, rows, cols, vals, v, Hv)</code></pre><p>Evaluate the product of the objective or Lagrangian Hessian given by <code>(rows, cols, vals)</code> in triplet format with the vector <code>v</code> in place. Only one triangle of the Hessian should be given.</p></div></section><section><div><pre><code class="language-none">Hv = hprod!(nlp, x, rows, cols, v, Hv)</code></pre><p>Evaluate the product of the objective Hessian at <code>x</code> with the vector <code>v</code> in place, where the objective Hessian is</p><div>\[σ ∇²f(x),\]</div><p>with <code>σ = obj_weight</code> . <code>(rows, cols)</code> should be the Hessian structure in triplet format.</p></div></section><section><div><pre><code class="language-none">Hv = hprod!(nlp, x, y, v, Hv; obj_weight=1.0)</code></pre><p>Evaluate the product of the Lagrangian Hessian at <code>(x,y)</code> with the vector <code>v</code> in place, with objective function scaled by <code>obj_weight</code>, where the Lagrangian Hessian is</p><div>\[∇²L(x,y) = σ ∇²f(x) + ∑ᵢ yᵢ ∇²cᵢ(x),\]</div><p>with <code>σ = obj_weight</code> .</p></div></section><section><div><pre><code class="language-none">Hv = hprod!(nlp, x, y, rows, cols, v, Hv)</code></pre><p>Evaluate the product of the Lagrangian Hessian at <code>(x,y)</code> with the vector <code>v</code> in place, where the Lagrangian Hessian is</p><div>\[∇²L(x,y) = σ ∇²f(x) + ∑ᵢ yᵢ ∇²cᵢ(x),\]</div><p>with <code>σ = obj_weight</code> . <code>(rows, cols)</code> should be the Hessian structure in triplet format.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearOperators.reset!" href="#LinearOperators.reset!"><code>LinearOperators.reset!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">reset!(counters)</code></pre><p>Reset evaluation counters</p></div></section><section><div><pre><code class="language-none">reset!(nlp)</code></pre><p>Reset evaluation count in <code>nlp</code></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.print" href="#Base.print"><code>Base.print</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">print(io, meta)</code></pre><p>Prints meta information - x0, nvar, ncon, etc.</p></div></section></article><h2 id="AbstractNLSModel-1"><a class="docs-heading-anchor" href="#AbstractNLSModel-1">AbstractNLSModel</a><a class="docs-heading-anchor-permalink" href="#AbstractNLSModel-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="NLPModels.residual" href="#NLPModels.residual"><code>NLPModels.residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Fx = residual(nls, x)</code></pre><p>Computes F(x), the residual at x.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.residual!" href="#NLPModels.residual!"><code>NLPModels.residual!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Fx = residual!(nls, x, Fx)</code></pre><p>Computes F(x), the residual at x.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_residual" href="#NLPModels.jac_residual"><code>NLPModels.jac_residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Jx = jac_residual(nls, x)</code></pre><p>Computes J(x), the Jacobian of the residual at x.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_coord_residual" href="#NLPModels.jac_coord_residual"><code>NLPModels.jac_coord_residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">(rows,cols,vals) = jac_coord_residual(nls, x)</code></pre><p>Computes the Jacobian of the residual at <code>x</code> in sparse coordinate format.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_coord_residual!" href="#NLPModels.jac_coord_residual!"><code>NLPModels.jac_coord_residual!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">vals = jac_coord_residual!(nls, x, vals)</code></pre><p>Computes the Jacobian of the residual at <code>x</code> in sparse coordinate format, rewriting <code>vals</code>. <code>rows</code> and <code>cols</code> are not rewritten.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_structure_residual" href="#NLPModels.jac_structure_residual"><code>NLPModels.jac_structure_residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">(rows,cols) = jac_structure_residual(nls)</code></pre><p>Returns the structure of the constraint&#39;s Jacobian in sparse coordinate format.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_structure_residual!" href="#NLPModels.jac_structure_residual!"><code>NLPModels.jac_structure_residual!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">(rows,cols) = jac_structure_residual!(nls, rows, cols)</code></pre><p>Returns the structure of the constraint&#39;s Jacobian in sparse coordinate format in place.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jprod_residual" href="#NLPModels.jprod_residual"><code>NLPModels.jprod_residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Jv = jprod_residual(nls, x, v)</code></pre><p>Computes the product of the Jacobian of the residual at x and a vector, i.e.,  J(x)*v.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jprod_residual!" href="#NLPModels.jprod_residual!"><code>NLPModels.jprod_residual!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Jv = jprod_residual!(nls, x, v, Jv)</code></pre><p>Computes the product of the Jacobian of the residual at x and a vector, i.e.,  J(x)*v, storing it in <code>Jv</code>.</p></div></section><section><div><pre><code class="language-none">Jv = jprod_residual!(nls, rows, cols, vals, v, Jv)</code></pre><p>Computes the product of the Jacobian of the residual given by <code>(rows, cols, vals)</code> and a vector, i.e.,  J(x)*v, storing it in <code>Jv</code>.</p></div></section><section><div><pre><code class="language-none">Jv = jprod_residual!(nls, x, rows, cols, v, Jv)</code></pre><p>Computes the product of the Jacobian of the residual at x and a vector, i.e.,  J(x)*v, storing it in <code>Jv</code>. The structure of the Jacobian is given by <code>(rows, cols)</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jtprod_residual" href="#NLPModels.jtprod_residual"><code>NLPModels.jtprod_residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Jtv = jtprod_residual(nls, x, v)</code></pre><p>Computes the product of the transpose of the Jacobian of the residual at x and a vector, i.e.,  J(x)&#39;*v.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jtprod_residual!" href="#NLPModels.jtprod_residual!"><code>NLPModels.jtprod_residual!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Jtv = jtprod_residual!(nls, x, v, Jtv)</code></pre><p>Computes the product of the transpose of the Jacobian of the residual at x and a vector, i.e.,  J(x)&#39;*v, storing it in <code>Jtv</code>.</p></div></section><section><div><pre><code class="language-none">Jtv = jtprod_residual!(nls, rows, cols, vals, v, Jtv)</code></pre><p>Computes the product of the transpose of the Jacobian of the residual given by <code>(rows, cols, vals)</code> and a vector, i.e.,  J(x)&#39;*v, storing it in <code>Jv</code>.</p></div></section><section><div><pre><code class="language-none">Jtv = jtprod_residual!(nls, x, rows, cols, v, Jtv)</code></pre><p>Computes the product of the transpose Jacobian of the residual at x and a vector, i.e.,  J(x)&#39;*v, storing it in <code>Jv</code>. The structure of the Jacobian is given by <code>(rows, cols)</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_op_residual" href="#NLPModels.jac_op_residual"><code>NLPModels.jac_op_residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Jx = jac_op_residual(nls, x)</code></pre><p>Computes J(x), the Jacobian of the residual at x, in linear operator form.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jac_op_residual!" href="#NLPModels.jac_op_residual!"><code>NLPModels.jac_op_residual!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Jx = jac_op_residual!(nls, x, Jv, Jtv)</code></pre><p>Computes J(x), the Jacobian of the residual at x, in linear operator form. The vectors <code>Jv</code> and <code>Jtv</code> are used as preallocated storage for the operations.</p></div></section><section><div><pre><code class="language-none">Jx = jac_op_residual!(nls, rows, cols, vals, Jv, Jtv)</code></pre><p>Computes J(x), the Jacobian of the residual given by <code>(rows, cols, vals)</code>, in linear operator form. The vectors <code>Jv</code> and <code>Jtv</code> are used as preallocated storage for the operations.</p></div></section><section><div><pre><code class="language-none">Jx = jac_op_residual!(nls, x, rows, cols, Jv, Jtv)</code></pre><p>Computes J(x), the Jacobian of the residual at x, in linear operator form. The vectors <code>Jv</code> and <code>Jtv</code> are used as preallocated storage for the operations. The structure of the Jacobian should be given by <code>(rows, cols)</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_residual" href="#NLPModels.hess_residual"><code>NLPModels.hess_residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">H = hess_residual(nls, x, v)</code></pre><p>Computes the linear combination of the Hessians of the residuals at <code>x</code> with coefficients <code>v</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_coord_residual" href="#NLPModels.hess_coord_residual"><code>NLPModels.hess_coord_residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">vals = hess_coord_residual(nls, x, v)</code></pre><p>Computes the linear combination of the Hessians of the residuals at <code>x</code> with coefficients <code>v</code> in sparse coordinate format.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_coord_residual!" href="#NLPModels.hess_coord_residual!"><code>NLPModels.hess_coord_residual!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">vals = hess_coord_residual!(nls, x, v, vals)</code></pre><p>Computes the linear combination of the Hessians of the residuals at <code>x</code> with coefficients <code>v</code> in sparse coordinate format, rewriting <code>vals</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_structure_residual" href="#NLPModels.hess_structure_residual"><code>NLPModels.hess_structure_residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">(rows,cols) = hess_structure_residual(nls)</code></pre><p>Returns the structure of the residual Hessian.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_structure_residual!" href="#NLPModels.hess_structure_residual!"><code>NLPModels.hess_structure_residual!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hess_structure_residual!(nls, rows, cols)</code></pre><p>Returns the structure of the residual Hessian in place.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jth_hess_residual" href="#NLPModels.jth_hess_residual"><code>NLPModels.jth_hess_residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Hj = jth_hess_residual(nls, x, j)</code></pre><p>Computes the Hessian of the j-th residual at x.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hprod_residual" href="#NLPModels.hprod_residual"><code>NLPModels.hprod_residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Hiv = hprod_residual(nls, x, i, v)</code></pre><p>Computes the product of the Hessian of the i-th residual at x, times the vector v.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hprod_residual!" href="#NLPModels.hprod_residual!"><code>NLPModels.hprod_residual!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Hiv = hprod_residual!(nls, x, i, v, Hiv)</code></pre><p>Computes the product of the Hessian of the i-th residual at x, times the vector v, and stores it in vector Hiv.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_op_residual" href="#NLPModels.hess_op_residual"><code>NLPModels.hess_op_residual</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Hop = hess_op_residual(nls, x, i)</code></pre><p>Computes the Hessian of the i-th residual at x, in linear operator form.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hess_op_residual!" href="#NLPModels.hess_op_residual!"><code>NLPModels.hess_op_residual!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Hop = hess_op_residual!(nls, x, i, Hiv)</code></pre><p>Computes the Hessian of the i-th residual at x, in linear operator form. The vector <code>Hiv</code> is used as preallocated storage for the operation.</p></div></section></article><h2 id="Derivative-Checker-1"><a class="docs-heading-anchor" href="#Derivative-Checker-1">Derivative Checker</a><a class="docs-heading-anchor-permalink" href="#Derivative-Checker-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="NLPModels.gradient_check" href="#NLPModels.gradient_check"><code>NLPModels.gradient_check</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Check the first derivatives of the objective at <code>x</code> against centered finite differences.</p><p>This function returns a dictionary indexed by components of the gradient for which the relative error exceeds <code>rtol</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.jacobian_check" href="#NLPModels.jacobian_check"><code>NLPModels.jacobian_check</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Check the first derivatives of the constraints at <code>x</code> against centered finite differences.</p><p>This function returns a dictionary indexed by (j, i) tuples such that the relative error in the <code>i</code>-th partial derivative of the <code>j</code>-th constraint exceeds <code>rtol</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hessian_check" href="#NLPModels.hessian_check"><code>NLPModels.hessian_check</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Check the second derivatives of the objective and each constraints at <code>x</code> against centered finite differences. This check does not rely on exactness of the first derivatives, only on objective and constraint values.</p><p>The <code>sgn</code> arguments refers to the formulation of the Lagrangian in the problem. It should have a positive value if the Lagrangian is formulated as</p><pre><code class="language-none">L(x,y) = f(x) + ∑ yⱼ cⱼ(x)</code></pre><p>e.g., as in <code>JuMPNLPModel</code>s, and a negative value if the Lagrangian is formulated as</p><pre><code class="language-none">L(x,y) = f(x) - ∑ yⱼ cⱼ(x)</code></pre><p>e.g., as in <code>AmplModel</code>s. Only the sign of <code>sgn</code> is important.</p><p>This function returns a dictionary indexed by functions. The 0-th function is the objective while the k-th function (for k &gt; 0) is the k-th constraint. The values of the dictionary are dictionaries indexed by tuples (i, j) such that the relative error in the second derivative ∂²fₖ/∂xᵢ∂xⱼ exceeds <code>rtol</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.hessian_check_from_grad" href="#NLPModels.hessian_check_from_grad"><code>NLPModels.hessian_check_from_grad</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Check the second derivatives of the objective and each constraints at <code>x</code> against centered finite differences. This check assumes exactness of the first derivatives.</p><p>The <code>sgn</code> arguments refers to the formulation of the Lagrangian in the problem. It should have a positive value if the Lagrangian is formulated as</p><pre><code class="language-none">L(x,y) = f(x) + ∑ yⱼ cⱼ(x)</code></pre><p>e.g., as in <code>JuMPNLPModel</code>s, and a negative value if the Lagrangian is formulated as</p><pre><code class="language-none">L(x,y) = f(x) - ∑ yⱼ cⱼ(x)</code></pre><p>e.g., as in <code>AmplModel</code>s. Only the sign of <code>sgn</code> is important.</p><p>This function returns a dictionary indexed by functions. The 0-th function is the objective while the k-th function (for k &gt; 0) is the k-th constraint. The values of the dictionary are dictionaries indexed by tuples (i, j) such that the relative error in the second derivative ∂²fₖ/∂xᵢ∂xⱼ exceeds <code>rtol</code>.</p></div></section></article><h2 id="Internal-1"><a class="docs-heading-anchor" href="#Internal-1">Internal</a><a class="docs-heading-anchor-permalink" href="#Internal-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="NLPModels.coo_prod!" href="#NLPModels.coo_prod!"><code>NLPModels.coo_prod!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">coo_prod!(rows, cols, vals, v, Av)</code></pre><p>Compute the product of a matrix <code>A</code> given by <code>(rows, cols, vals)</code> and the vector <code>v</code>. The result is stored in <code>Av</code>, which should have length equals to the number of rows of <code>A</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.coo_sym_prod!" href="#NLPModels.coo_sym_prod!"><code>NLPModels.coo_sym_prod!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">coo_sym_prod!(rows, cols, vals, v, Av)</code></pre><p>Compute the product of a symmetric matrix <code>A</code> given by <code>(rows, cols, vals)</code> and the vector <code>v</code>. The result is stored in <code>Av</code>, which should have length equals to the number of rows of <code>A</code>. Only one triangle of <code>A</code> should be passed.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.increment!" href="#NLPModels.increment!"><code>NLPModels.increment!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">increment!(nlp, s)</code></pre><p>Increment counter <code>s</code> of problem <code>nlp</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="NLPModels.decrement!" href="#NLPModels.decrement!"><code>NLPModels.decrement!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">decrement!(nlp, s)</code></pre><p>Decrement counter <code>s</code> of problem <code>nlp</code>.</p></div></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorial/">« Tutorial</a><a class="docs-footer-nextpage" href="../reference/">Reference »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 28 February 2020 20:19">Friday 28 February 2020</span>. Using Julia version 1.3.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
